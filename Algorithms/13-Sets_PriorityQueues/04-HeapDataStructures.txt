Heap Data Structure
The mythical manticore had lion’s body, human head, and scorpion tail. Priority queues are commonly
constructed with minheaps, with similarly unusual characteristics (not heap where memory allocations
occur, although regrettably the same word). Not to be outdone by manticores, heaps act like queues, 
manage data like trees, and are stored in arrays. Rather than extraordinary speed in a few aspects, 
heaps strike a balance: great insertion, good deletion, and great extraction (in monotonic priority order). 
How does this creature do it? A heap isn’t fully sorted. It knows the lowest value, and can quickly 
rearrange to stay “sorted just enough” for the next ask. Insertion similarly does just enough to stay 
“somewhat sorted” without extra work. These “lazy” heaps work this way: first, data are arranged in
binary nodes. Second, minheap node must have a value less / equal to its children’s. Third, minheaps
are complete trees: all nodes have two children except at deepest level, where nodes populate from 
leftmost extending right. That’s it! Here we assume a minheap, although we easily invert rules for 
maxheap. The only behavior difference: maxheaps extract values largest to smallest, not lowest-first. 
Here’s the next interesting detail: instead of using actual binary tree nodes, a minheap puts values into
an array, using array indices to track parent-child relationships between values. Specifically, value at 
index N has children at indices 2N and 2N+1, and its parent can always be found at N/2. The root of the
heap is located at index 1 (index 0 usually holds some other value). Thus, tree traversal from arbitrary
nodes is quick. With this in mind, four of the basic data structure methods (size(), isEmpty(), 
top(), contains(val)) are trivial. The performance of contains(val) is horrid (effectively, it must 
search the entire underlying array). The insert() and extract() methods are more interesting.
For insert(val), we know that our tree’s size will grow by one. Because our tree is complete, we
know where this new node will be added (our Array.length will grow by one). Although that likely
isn’t where it belongs, we put the new value there to start. We then undergo a “promote” process for 
node, comparing it to parent. If value is less than parent’s, we swap them and try to promote it again
(comparing to its new post-swap parent). Once it can no longer be promoted, insertion is complete. 
Build the following methods on a new class called a MinHeap:
 Heap: Constructor
Create a MinHeap constructor function.
 Heap: Size
Return the number of values in the MinHeap.
 Heap: Contains
Return whether a given val is within the heap. 
 Heap: Is Empty
Return whether the heap is empty. 
 Heap: Top
Return (not remove) the heap’s minimum value. 
 Heap: Insert
Add the given value to our heap.
Let us continue our development of the MinHeap data structure. Previously, we developed the ability to
add elements. Now we will build a method to remove the top element – we’ll call it extract(). 
For this discussion, keep in mind that although we are storing the element values in an array, we are
still thinking about the collection of values as a binary tree. With this in mind, below I refer to values and 
nodes. By nodes, I just mean the array index where the value is found. 
For extract(), we know that our tree size will shrink by one node. Because it is always a complete
tree, we know that the node to be removed is the last node. In other words, our array will become 
shorter, by one. We also know which value needs to be removed from our array, and it is the first value,
not the last value. To use a metaphor, we remove the first person, and the last chair. So, our challenge, 
when we extract a value from our heap, is how to minimally rearrange values in the tree so that all the
remaining nodes are occupied by the remaining values, in a way that satisfies all the heap rules. Doing 
this in a minimal way is the hallmark of a heap. 
We start by considering the last value in the heap – the one sitting in the array index we want to
remove. We give that value an unusual opportunity: we move it to the root for a short time. From there,
we will put the value through a “demote” process to shift it downward in the tree to a more suitable spot.
What does this “demote” process entail? After swapping the value into the root spot, we first compare it 
to its two new children. If either of them has a lower value than it does, we swap it with the lower one, 
then repeat this “demote” process with that same value in its new spot, until it has no children with 
lower values (this might not happen until it has no children at all!). Once it can no longer be demoted, 
the extraction process is complete. 
With extract(), our basic data structure implementation is complete. Additionally, we would like the 
ability to pass in an array and have the Heap adopt that array as its own, quickly repairing it to a state
of compliance with the Heap rules. First, change the Heap constructor to optionally accept an array. 
Also create the heapify method that accepts and repairs this array after the Heap has been created.
 Heap: Extract
Create a MinHeap method that removes the
heap’s minimum value and returns it. 
 Heap: Heapify Array
Create a heap method that accepts an array as 
its own, and turns it into a rule-abiding MinHeap.
 Heap Sort
Lance discovers with glee that if one heapifies an unsorted array, then extracts values, the array is 
sorted in O(NlogN) time – as fast as quick sort or merge sort, the usual winners in generalized sorting!
He views this as solid proof that the Heap truly is “the crown prince of data structures.” Write a
standalone function heapSort(arr) that accepts an unsorted array and uses a heap to sort it. 
Second: do this in-place without creating a second array.
 Median of Data Stream
With a separate function addValue(val), you will be given a continuous stream of data, one value at
a time. At any moment, with reasonable performance you need to be able to return the median value. 
(What is reasonable performance?) Recall that the median of an even number of elements is the 
average of the two middle values. 
Before next chapter, here are a few other Queue/Stack problems to keep you thinking. Have fun! 
 Queue from Two Stacks
Using only Stack objects (not other data 
structures such as linked lists or arrays), 
implement a Queue. 
 Priority Queue from Two Stacks
Using only Stack objects (not other data 
structures such as lists or arrays), implement a 
Priority Queue. 
 Comparing Stacks/Queues to Other Data Structures
By now we have studied a few different data structures: array, SList, DList, BST, SLQueue, 
CirQueue, ArrStack, Deque, PriQueue. Each of these could be built as a set instead of a multiset
(rejecting duplicate values instead of accepting them). We will not require you to build all the possible 
variants, but below we list them for completeness. Those that are bolded are ones you’ve already built
previously; those underlined are highly recommended. In most cases, creating these will require only
small adjustments to code you’ve already written. 
Array (random-access multiset)
Array without duplicates (random-access set)
SList (forward-iterated insertable multiset)
SList without duplicates (forward-iterated 
insertable set)
DList (double-iterated insertable multiset)
DList without duplicates (double-iterated 
insertable set)
Binary Search Tree (ordered multiset)
Binary Search Tree without duplicates 
(ordered set)
SLQueue (sequential multiset)
SLQueue without duplicates (sequential set)
CirQueue (sequential multiset)
CirQueue without duplicates (sequential set)
SLStack (sequential multiset)
SLStack without duplicates (sequential set)
ArrStack (sequential multiset)
ArrStack without duplicates (sequential set)
Deque (double-sequential multiset)
Deque without duplicates (double-sequential set)
PriQueue (forward-ordered multiset)
PriQueue without duplicates (forward-ordered set)
Next chapter we’ll build these:
Associative Array (unordered multiset)
Associative Array without duplicates (unordered set).